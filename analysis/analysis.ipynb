{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacob Roach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed Packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection and Feature Engineering\n",
    "Before any modeling was performed, the necessary data was collected using two distinct platforms. The first data that was collected was Twitter data. This was done using the Twitter Developer API, as well as the `tweepy` module. Tweets containing the word \"bitcoin\" were streamed for several days. This data was written to a `.pkl` file, and saved for later feature engineering.\n",
    "\n",
    "The other data that was collected was the value of a single Bitcoin. During the same interval (plus twenty-four hours after the last Tweet was recorded) that the Twitter data was collected, the value of a Bitcoin was recorded each minute, along with the corresponding time stamp.\n",
    "\n",
    "Once the Twitter and Bitcoin data was recorded, further feature engineering was employed. For each Tweet stored, the corresponding price of Bitcoin at the time the Tweet was made was added as the `inital_price` for the Tweet. Then, for each Tweet, if the price of Bitcoin increased within three hours of the time the Tweet was made, the feature `increase` was assigned a value of `1`. Otherwise, `increase` is assigned the value of `0`.\n",
    "\n",
    "Finally, for each Tweet recorded, the text of that Tweet is cleaned and standardized. This cleaned Tweet is then BERTified, and a vector of length 384 is returned. This vector is stored as the `embedded` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the training data.\n",
    "data = pd.read_pickle(\"../data/training_data.pkl\")\n",
    "\n",
    "# Reset the index, convert each embedding to an array.\n",
    "data = data.reset_index(drop=True)\n",
    "data[\"embedding\"] = data[\"embedding\"].apply(lambda x: np.asarray(x))\n",
    "\n",
    "# Create a new train-test split (for aggregation).\n",
    "stamps = np.unique(data.time)\n",
    "data.set_index([\"time\"], inplace=True)\n",
    "test_stamps = np.random.choice(stamps, size=int(stamps.shape[0] * .20))\n",
    "test_data = data.loc[test_stamps, :]\n",
    "train_data = data.loc[~data.index.isin(test_stamps), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training data has been read in, the data will be quickly inspected, to show the reader the nature of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 336030 rows in the DataFrame.\n",
      "There are 174261 records with an increase, and 161769 with a decrease.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Investigate the DataFrame.\n",
    "print(\"There are\", len(data), \"rows in the DataFrame.\")\n",
    "print(\"There are\", len(data.loc[data[\"increase\"] == 1, ]), \"records with an increase, and\", \n",
    "        len(data.loc[data[\"increase\"] == 0, ]), \"with a decrease.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing data.\n",
    "x_train = train_data[\"embedding\"]\n",
    "y_train = train_data[\"increase\"]\n",
    "x_test = test_data[\"embedding\"]\n",
    "y_test = test_data[\"increase\"]\n",
    "\n",
    "# Conver to Tensors.\n",
    "x_train = tf.convert_to_tensor(x_train.to_list())\n",
    "y_train = tf.convert_to_tensor(y_train.to_list())\n",
    "x_test = tf.convert_to_tensor(x_test.to_list())\n",
    "y_test = tf.convert_to_tensor(y_test.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8529/8529 [==============================] - 19s 2ms/step - loss: 0.6795 - accuracy: 0.5578 - val_loss: 0.6823 - val_accuracy: 0.5526\n",
      "Epoch 2/5\n",
      "8529/8529 [==============================] - 19s 2ms/step - loss: 0.6691 - accuracy: 0.5779 - val_loss: 0.6783 - val_accuracy: 0.5596\n",
      "Epoch 3/5\n",
      "8529/8529 [==============================] - 17s 2ms/step - loss: 0.6636 - accuracy: 0.5877 - val_loss: 0.6785 - val_accuracy: 0.5627\n",
      "Epoch 4/5\n",
      "8529/8529 [==============================] - 17s 2ms/step - loss: 0.6594 - accuracy: 0.5940 - val_loss: 0.6782 - val_accuracy: 0.5653\n",
      "Epoch 5/5\n",
      "8529/8529 [==============================] - 18s 2ms/step - loss: 0.6560 - accuracy: 0.5981 - val_loss: 0.6783 - val_accuracy: 0.5716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x174429220>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model.\n",
    "input_layer = Input((384,))\n",
    "dense = Dense(128, activation=\"relu\")(input_layer)\n",
    "output = Dense(2, activation=\"softmax\")(dense)  # Output values is the number of classes.\n",
    "rnn_model = Model(input_layer, output)\n",
    "\n",
    "# Compile the model.\n",
    "rnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model. MAKE SURE TO CHANGE THIS TO 25 EPOCHS.\n",
    "rnn_model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8529/8529 [==============================] - 3932s 460ms/step - loss: 0.6943 - accuracy: 0.5216 - val_loss: 0.6931 - val_accuracy: 0.5021\n",
      "Epoch 2/5\n",
      "8529/8529 [==============================] - 4154s 487ms/step - loss: 0.6932 - accuracy: 0.5224 - val_loss: 0.6931 - val_accuracy: 0.5021\n",
      "Epoch 3/5\n",
      "8529/8529 [==============================] - 4199s 492ms/step - loss: 0.6932 - accuracy: 0.5224 - val_loss: 0.6931 - val_accuracy: 0.5021\n",
      "Epoch 4/5\n",
      "8529/8529 [==============================] - 4141s 486ms/step - loss: 0.6932 - accuracy: 0.5224 - val_loss: 0.6931 - val_accuracy: 0.5021\n",
      "Epoch 5/5\n",
      "8529/8529 [==============================] - 4830s 566ms/step - loss: 0.6932 - accuracy: 0.5224 - val_loss: 0.6931 - val_accuracy: 0.5021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x170ad7940>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a new model.\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(384,1)))\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "model.add(layers.Dense(10))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other models to try:\n",
    "### - SVM\n",
    "### - Naive Bayes\n",
    "### - kNN\n",
    "### - Random Forrests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to DataFrame.\n",
    "predictions = rnn_model.predict(x_test)\n",
    "predictions = np.array(list(map(lambda x: 0 if x[0] > x[1] else 1, predictions)))\n",
    "test_data[\"prediction\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>total_count</th>\n",
       "      <th>pred_count</th>\n",
       "      <th>pred_perc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-16 09:15:00</th>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>182</td>\n",
       "      <td>0.831050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-16 09:30:00</th>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "      <td>161</td>\n",
       "      <td>0.755869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-16 09:31:00</th>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>0.756477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-16 09:33:00</th>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>136</td>\n",
       "      <td>0.819277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-16 09:40:00</th>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>163</td>\n",
       "      <td>0.806931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-17 18:40:00</th>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>95</td>\n",
       "      <td>0.521978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-17 18:43:00</th>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>95</td>\n",
       "      <td>0.616883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-17 18:54:00</th>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>75</td>\n",
       "      <td>0.503356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-17 18:55:00</th>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>89</td>\n",
       "      <td>0.597315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-17 18:58:00</th>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>77</td>\n",
       "      <td>0.478261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     actual  total_count  pred_count  pred_perc\n",
       "time                                                           \n",
       "2022-02-16 09:15:00       0          219         182   0.831050\n",
       "2022-02-16 09:30:00       0          213         161   0.755869\n",
       "2022-02-16 09:31:00       0          193         146   0.756477\n",
       "2022-02-16 09:33:00       1          166         136   0.819277\n",
       "2022-02-16 09:40:00       0          202         163   0.806931\n",
       "...                     ...          ...         ...        ...\n",
       "2022-02-17 18:40:00       0          182          95   0.521978\n",
       "2022-02-17 18:43:00       0          154          95   0.616883\n",
       "2022-02-17 18:54:00       0          149          75   0.503356\n",
       "2022-02-17 18:55:00       0          149          89   0.597315\n",
       "2022-02-17 18:58:00       1          161          77   0.478261\n",
       "\n",
       "[369 rows x 4 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new DataFrame.\n",
    "aggregated = pd.DataFrame(test_stamps, columns=[\"time\"])\n",
    "\n",
    "# Get the actual.\n",
    "agg_count = test_data.loc[:, [\"increase\"]].groupby(\"time\").count()\n",
    "agg_sum = test_data.loc[:, [\"increase\", \"prediction\"]].groupby(\"time\").sum()\n",
    "\n",
    "# Change column names.\n",
    "agg_count = agg_count.rename(columns={\"increase\": \"total_count\"})\n",
    "agg_sum = agg_sum.rename(columns={\"increase\": \"actual\", \"prediction\": \"pred_count\"})\n",
    "\n",
    "# Final join.\n",
    "agg = agg_count.join(agg_sum)\n",
    "agg[\"actual\"] = agg[\"actual\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "agg[\"pred_perc\"] = agg[\"pred_count\"] / agg[\"total_count\"]\n",
    "agg = agg[[\"actual\", \"total_count\", \"pred_count\", \"pred_perc\"]]\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_count</th>\n",
       "      <th>pred_count</th>\n",
       "      <th>pred_perc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184.400000</td>\n",
       "      <td>108.567568</td>\n",
       "      <td>0.605305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186.978261</td>\n",
       "      <td>136.603261</td>\n",
       "      <td>0.736755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total_count  pred_count  pred_perc\n",
       "actual                                    \n",
       "0        184.400000  108.567568   0.605305\n",
       "1        186.978261  136.603261   0.736755"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best cutoff.\n",
    "check = agg.groupby(\"actual\").mean()\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e5788945c2802237ac72a84c772d7bec8af624c1002577fbf4f87a46c8d1d03"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
