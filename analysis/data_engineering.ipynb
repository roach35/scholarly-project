{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages.\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data.\n",
    "crypto = pd.read_pickle(\"../data/crypto_3_9.pkl\")\n",
    "tweets = pd.read_pickle(\"../data/tweets_3_9.pkl\")\n",
    "\n",
    "# Download the BERT model.\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function.\n",
    "def get_max(min_stamp, price):\n",
    "    max_stamp = min_stamp + timedelta(hours=3)\n",
    "    mask = (crypto[\"stamp\"] > min_stamp) & (crypto[\"stamp\"] < max_stamp)\n",
    "    sub_df = crypto.loc[mask]\n",
    "    max_price = sub_df.price.max()\n",
    "\n",
    "    # Create the difference.\n",
    "    difference = (max_price - price) / price\n",
    "    \n",
    "    # Return. THIS IS IMPORTANT.\n",
    "    if difference > .0025:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function.\n",
    "crypto[\"increase\"] = crypto.apply(lambda x: get_max(x[0], x[2]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the data.\n",
    "training_data = tweets.merge(crypto, left_on=\"time\", right_on=\"stamp\")\n",
    "training_data = training_data.set_index(\"tweet_id\")\n",
    "training_data = training_data.loc[:, [\"time\", \"tweet\", \"increase\"]]\n",
    "training_data[\"embedding\"] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/hw5qr0qd5t5fc8_xskflkdg80000gn/T/ipykernel_7329/1206328388.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_data[\"embedding\"] = sub_data[\"tweet\"].apply(bert_tweets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n",
      "Ignored unknown kwarg option direction\n"
     ]
    }
   ],
   "source": [
    "# BERT, in chunks.\n",
    "def bert_tweets(tweet):\n",
    "    \"\"\"\n",
    "    BERTify the Tweets.\n",
    "    \n",
    "    :param: tweet\n",
    "    :return: encoded Tweet\n",
    "    \"\"\"\n",
    "    \n",
    "    # BERTify the chunk.\n",
    "    return model.encode(str(tweet))\n",
    "\n",
    "# Loop.\n",
    "step = 3000\n",
    "for min_index in range(270000, training_data.shape[0], step):\n",
    "    # Create a sub DataFrame.\n",
    "    max_index = min_index + step\n",
    "    sub_data = training_data.iloc[min_index:max_index, :]\n",
    "    sub_data[\"embedding\"] = sub_data[\"tweet\"].apply(bert_tweets)\n",
    "    sub_data.to_pickle(f\"../data/embedded/bert_{min_index}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of files.\n",
    "read_files = list()\n",
    "\n",
    "# Stitch the written files back together.\n",
    "for file_name in glob.glob(\"../data/embedded/*.pkl\"):\n",
    "    read_files.append(pd.read_pickle(file_name))\n",
    "\n",
    "# Concat, write the data.\n",
    "stitched_data = pd.concat(read_files, axis=0)\n",
    "stitched_data.to_pickle(\"../data/training_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e5788945c2802237ac72a84c772d7bec8af624c1002577fbf4f87a46c8d1d03"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('scholarly_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
